<?xml version="1.0" encoding="utf-8" standalone="yes" ?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
  <channel>
    <title>data | Mike Nguyen</title>
    <link>https://mikenguyen.netlify.app/tag/data/</link>
      <atom:link href="https://mikenguyen.netlify.app/tag/data/index.xml" rel="self" type="application/rss+xml" />
    <description>data</description>
    <generator>Wowchemy (https://wowchemy.com)</generator><language>en-us</language><copyright>© Mike Nguyen 2024</copyright><lastBuildDate>Sat, 20 Feb 2021 00:00:00 +0000</lastBuildDate>
    <image>
      <url>https://mikenguyen.netlify.app/media/social_sharing_image.png</url>
      <title>data</title>
      <link>https://mikenguyen.netlify.app/tag/data/</link>
    </image>
    
    <item>
      <title>fix for &#34;cannot allocate vector of size&#34;</title>
      <link>https://mikenguyen.netlify.app/post/fix-for-cannot-allocate-vector-of-size/</link>
      <pubDate>Sat, 20 Feb 2021 00:00:00 +0000</pubDate>
      <guid>https://mikenguyen.netlify.app/post/fix-for-cannot-allocate-vector-of-size/</guid>
      <description>
&lt;script src=&#34;https://mikenguyen.netlify.app/post/fix-for-cannot-allocate-vector-of-size/index.en_files/header-attrs/header-attrs.js&#34;&gt;&lt;/script&gt;


&lt;p&gt;More package author’s introduction, please access this &lt;a href=&#34;https://cran.r-project.org/web/packages/disk.frame/readme/README.html&#34;&gt;link&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;Instead of loading everything at once into your RAM, you divide your data into chunks.
To quote author of the &lt;code&gt;disk.frame&lt;/code&gt; package: “we go from”R can only deal with data that fits in RAM&#34; to “R can deal with any data that fits on disk”.&#34; While &lt;code&gt;data.frame&lt;/code&gt; uses in-RAM to process, &lt;code&gt;disk.frame&lt;/code&gt; uses hard drive to store and process data.&lt;code&gt;disk.frame&lt;/code&gt; also allows parallel processing.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;library(&amp;quot;disk.frame&amp;quot;) 
# setup_disk.frame() # sets up background workers equal to the number of CPU c res setup_disk.frame(workers =\ 2) \# or you number of workers options(future.globals.maxSize = \Inf) # large dataset can be transferred between sessions
# attr(data.df, &amp;quot;path&amp;quot;) # path to where the disk.frame is 


# to convert data.frame to a     disk.frame
data.df &amp;lt;- as.disk.frame(original_data_frame)

# to convert one large CSV
# takes care of splitting large CSV into smaller ones 
diskf &amp;lt;- disk.frame::csv_to_disk.frame(path_to_csv_file) # you can also specify,outdir = , overwrite = T.     

# to convert multiple CSV
multiple_CSV = c(path_to_csv_file1,path_to_csv_file2)
diskf = disk.frame::csv_to_disk.frame(multiple_CSV)

# for faster performance, specify which column to manipulate
result  = df %&amp;gt;% 
  srep(c(&amp;quot;column1&amp;quot;,&amp;quot;column2&amp;quot;)) %&amp;gt;%
  dplyr::filter()&lt;/code&gt;&lt;/pre&gt;
</description>
    </item>
    
    <item>
      <title>Connect WRDS in R</title>
      <link>https://mikenguyen.netlify.app/post/connect-wrds-in-r/</link>
      <pubDate>Tue, 29 Dec 2020 00:00:00 +0000</pubDate>
      <guid>https://mikenguyen.netlify.app/post/connect-wrds-in-r/</guid>
      <description>


&lt;p&gt;Connect from R to Wharton Research Data Services&lt;/p&gt;
&lt;p&gt;to set up connection from R to WRDS (&lt;a href=&#34;https://wrds-www.wharton.upenn.edu/pages/support/programming-wrds/programming-r/r-from-your-computer/&#34;&gt;here&lt;/a&gt;)&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;library(RPostgres)
library(dplyr)


# I&amp;#39;ve set up wrds connection before hand. 
# Please use your username and password here.
wrds &amp;lt;- dbConnect(
  Postgres(),
  host = &amp;#39;wrds-pgdata.wharton.upenn.edu&amp;#39;,
  port = 9737,
  dbname = &amp;#39;wrds&amp;#39;,
  sslmode = &amp;#39;require&amp;#39;,
  user = Sys.getenv(&amp;quot;wrds_user&amp;quot;),
  pass = Sys.getenv(&amp;quot;wrds_pass&amp;quot;)
)
knitr::opts_chunk$set(message = FALSE)&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Example&lt;/p&gt;
&lt;p&gt;Check variables (column headers) in COMP ANNUAL FUNDAMENTAL&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;res &amp;lt;- dbSendQuery(
  wrds,
  &amp;quot;select column_name
                   from information_schema.columns
                   where table_schema=&amp;#39;compa&amp;#39;
                   and table_name=&amp;#39;funda&amp;#39;
                   order by column_name&amp;quot;
)
# data &amp;lt;- dbFetch(res, n=-1) 
data &amp;lt;- dbFetch(res, n = 10)
dbClearResult(res) # closes the connection
head(data)&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;##   column_name
## 1       acchg
## 2        acco
## 3       accrt
## 4     acctchg
## 5     acctstd
## 6        acdo&lt;/code&gt;&lt;/pre&gt;
&lt;div id=&#34;overview&#34; class=&#34;section level2&#34;&gt;
&lt;h2&gt;Overview&lt;/h2&gt;
&lt;p&gt;All data libraries available at WRDS&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;res &amp;lt;- dbSendQuery(wrds, &amp;quot;select distinct table_schema
                   from information_schema.tables
                   order by table_schema&amp;quot;)
all_lib &amp;lt;- dbFetch(res, n=-1)
dbClearResult(res)
head(all_lib)&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;##           table_schema
## 1                  aha
## 2     aha_hcris_3years
## 3 aha_hcris_3years_old
## 4     aha_hcris_recent
## 5 aha_hcris_recent_old
## 6 aha_it_survey_3years&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;datasets within a given library&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;res &amp;lt;- dbSendQuery(wrds, &amp;quot;select distinct table_name
                   from information_schema.columns
                   where table_schema=&amp;#39;comp_na_daily_all&amp;#39;
                   order by table_name&amp;quot;)
df_in_lib &amp;lt;- dbFetch(res, n=-1)
dbClearResult(res)
head(df_in_lib)&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;##      table_name
## 1      aco_amda
## 2      aco_imda
## 3   aco_indfnta
## 4   aco_indfntq
## 5 aco_indfntytd
## 6    aco_indsta&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;variables within a given dataset&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;res &amp;lt;- dbSendQuery(wrds, &amp;quot;select column_name
                   from information_schema.columns
                   where table_schema=&amp;#39;comp_na_daily_all&amp;#39;
                   and table_name=&amp;#39;funda&amp;#39;
                   order by column_name&amp;quot;)
variables &amp;lt;- dbFetch(res, n=-1)
dbClearResult(res)
head(variables)&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;##   column_name
## 1       acchg
## 2        acco
## 3       accrt
## 4     acctchg
## 5     acctstd
## 6        acdo&lt;/code&gt;&lt;/pre&gt;
&lt;/div&gt;
&lt;div id=&#34;specific-example&#34; class=&#34;section level2&#34;&gt;
&lt;h2&gt;Specific Example&lt;/h2&gt;
&lt;p&gt;Get advertising and R&amp;amp;D data&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;# from comp_na_daily_all.funda
res &amp;lt;- dbSendQuery(wrds, &amp;quot;select gvkey, fyear, xad, xrd
                   from comp_na_daily_all.funda
                   where fyear between 2000 and 2010 
                     and xad is not null 
                     and xrd is not null&amp;quot;)

# res &amp;lt;- dbSendQuery(wrds, &amp;quot;select gvkey, fyear
#                    from comp_na_daily_all.funda
#                    where fyear between 2000 and 2020&amp;quot;)

data &amp;lt;- dbFetch(res, n=10) |&amp;gt; 
# data &amp;lt;- dbFetch(res, n=-1) |&amp;gt; 
    unique()
dbClearResult(res)
head(data)&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;##    gvkey fyear     xad     xrd
## 1 001050  2000   0.188   0.140
## 2 001084  2000   1.711   0.036
## 3 001104  2000   3.170   0.046
## 4 001111  2000  16.500  41.396
## 5 001117  2000   0.161   1.175
## 6 001161  2000 148.000 641.799&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Get industry data&lt;/p&gt;
&lt;p&gt;In WRDS, the industry classifications visible on the web version differ from those in the code version. This discrepancy arises because the web dataset undergoes (behind the scene) a merging process where different variables are combined to produce the final table. Consequently, in the library dataset comp_na_daily_all.funda, key classifications such as gind, gsubind, naics, and sic are absent. Instead, it includes naics historical and sic historical, which often contain incomplete data. To obtain a complete view, users must merge this dataset with the &lt;a href=&#34;https://wrds-www.wharton.upenn.edu/data-dictionary/comp_na_daily_all/names/&#34;&gt;industry dataset&lt;/a&gt;.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;# get industry data
res &amp;lt;- dbSendQuery(wrds,
                   &amp;quot;select gvkey, gind, gsubind, naics, sic
                   from comp_na_daily_all.names&amp;quot;)
ind &amp;lt;- dbFetch(res, n = -1)
dbClearResult(res)
head(ind)&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;##    gvkey   gind  gsubind  naics  sic
## 1 001000   &amp;lt;NA&amp;gt;     &amp;lt;NA&amp;gt;   &amp;lt;NA&amp;gt; 3089
## 2 001001 253010 25301040    722 5812
## 3 001002   &amp;lt;NA&amp;gt;     &amp;lt;NA&amp;gt;   &amp;lt;NA&amp;gt; 3825
## 4 001003 255040 25504040 442110 5712
## 5 001004 201010 20101010 423860 5080
## 6 001005   &amp;lt;NA&amp;gt;     &amp;lt;NA&amp;gt;   &amp;lt;NA&amp;gt; 3724&lt;/code&gt;&lt;/pre&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;df &amp;lt;- data |&amp;gt; 
    left_join(ind)

head(df)&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;##    gvkey fyear     xad     xrd   gind  gsubind  naics  sic
## 1 001050  2000   0.188   0.140 202010 20201050 333413 3564
## 2 001084  2000   1.711   0.036 502030 50203010 519290 7370
## 3 001104  2000   3.170   0.046 202010 20201060 332215 3420
## 4 001111  2000  16.500  41.396 451030 45103030 511210 7372
## 5 001117  2000   0.161   1.175 452010 45201020 334220 3663
## 6 001161  2000 148.000 641.799 453010 45301020 334413 3674&lt;/code&gt;&lt;/pre&gt;
&lt;/div&gt;
</description>
    </item>
    
    <item>
      <title>Patent Databases</title>
      <link>https://mikenguyen.netlify.app/post/patent-databases/</link>
      <pubDate>Wed, 09 Dec 2020 00:00:00 +0000</pubDate>
      <guid>https://mikenguyen.netlify.app/post/patent-databases/</guid>
      <description>
&lt;link href=&#34;https://mikenguyen.netlify.app/rmarkdown-libs/anchor-sections/anchor-sections.css&#34; rel=&#34;stylesheet&#34; /&gt;
&lt;script src=&#34;https://mikenguyen.netlify.app/rmarkdown-libs/anchor-sections/anchor-sections.js&#34;&gt;&lt;/script&gt;


&lt;p&gt;Comprehensive patent data can be found &lt;a href=&#34;https://eml.berkeley.edu/~bhhall/patents.html&#34;&gt;here&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;United States&lt;/strong&gt;&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;a href=&#34;https://sites.google.com/site/patentdataproject/Home/downloads&#34;&gt;NBER patent data&lt;/a&gt; or &lt;a href=&#34;https://eml.berkeley.edu/~bhhall/NBER06.html&#34;&gt;link&lt;/a&gt;
&lt;ul&gt;
&lt;li&gt;Search link for individual patent: &lt;a href=&#34;http://patft.uspto.gov/&#34;&gt;link&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;https://developer.uspto.gov/api-catalog&#34;&gt;Patent API&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;&lt;/li&gt;
&lt;li&gt;USPTO - United States patent and Trademark Office
&lt;ul&gt;
&lt;li&gt;&lt;a href=&#34;https://www.uspto.gov/web/offices/ac/ido/oeip/taf/reports_topo.htm&#34;&gt;Patent ranking by orgs&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;https://bulkdata.uspto.gov/&#34;&gt;Bulk Data Storage System:&lt;/a&gt; repository for raw public bulk data
&lt;ul&gt;
&lt;li&gt;&lt;a href=&#34;https://www.uspto.gov/ip-policy/economic-research/research-datasets&#34;&gt;For Researcher&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;https://www.uspto.gov/learning-and-resources/electronic-data-products/patent-assignment-dataset&#34;&gt;Patent Assignment Dataset&lt;/a&gt; details information of patent assignment since 1970 with &lt;a href=&#34;https://www.uspto.gov/sites/default/files/documents/pat_assign_dataset_schema.pdf&#34;&gt;schema&lt;/a&gt; and &lt;a href=&#34;https://www.uspto.gov/sites/default/files/documents/USPTO_Patents_Assignment_Dataset_WP.pdf&#34;&gt;description&lt;/a&gt; and &lt;a href=&#34;https://github.com/USPTO/PatentPublicData&#34;&gt;code&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;https://www.patentsview.org/download/pregrantpublications.html&#34;&gt;Pre-Grant Publications Data Download Tables&lt;/a&gt; with example &lt;a href=&#34;https://github.com/PatentsView/PatentsView-Code-Snippets/blob/master/04_bulk_pregrant_read_in/R%20Scripts/rawassignee.Rmd&#34;&gt;code&lt;/a&gt; note that organizaiton here is different from Compustat and CRSP, hard to match.&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;https://ped.uspto.gov/peds/&#34;&gt;Patent Examiniation Data system&lt;/a&gt;: records of USPTO patent application, patent filing status and transaction history data&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;https://www.uspto.gov/learning-and-resources/electronic-data-products/trademark-assignment-dataset&#34;&gt;Trademark Assignment Dataset&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;https://www.uspto.gov/learning-and-resources/electronic-data-products/patent-assignment-dataset&#34;&gt;Patent Assignment Dataset&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;https://zenodo.org/record/3594694#.X9hH59hKgdW&#34;&gt;Duke Innovation&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;https://iu.app.box.com/v/patents&#34;&gt;Matched US patents to CRSP 1926 - 2010&lt;/a&gt;: Leonid Kogan, Dimitris Papanikolaou, Amit Seru, and Noah Stoffman. &lt;a href=&#34;https://paper.dropbox.com/doc/U.S.-Patent-Data-1926-2010-t5nuNWnTH1InM0gyxkizL&#34;&gt;Description&lt;/a&gt;
&lt;ul&gt;
&lt;li&gt;&lt;a href=&#34;https://kelley.iu.edu/nstoffma/&#34;&gt;Maintainer&lt;/a&gt; with &lt;a href=&#34;https://github.com/KPSS2017/Technological-Innovation-Resource-Allocation-and-Growth-Extended-Data&#34;&gt;code&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;&lt;a href=&#34;https://www.uspto.gov/patents-application-process/applying-online/patent-number&#34;&gt;Recognizing Patent&lt;/a&gt;:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Utility: 6 - 8 digits lasts for 20 years from the filed date&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;&lt;a href=&#34;https://www.uspto.gov/patent/laws-and-regulations/patent-term-calculator&#34;&gt;Changes to Patent Terms&lt;/a&gt;&lt;/p&gt;
&lt;table&gt;
&lt;thead&gt;
&lt;tr class=&#34;header&#34;&gt;
&lt;th&gt;Year filed&lt;/th&gt;
&lt;th&gt;Maximum term of validity&lt;/th&gt;
&lt;th&gt;Act&lt;/th&gt;
&lt;/tr&gt;
&lt;/thead&gt;
&lt;tbody&gt;
&lt;tr class=&#34;odd&#34;&gt;
&lt;td&gt;1790–1835&lt;/td&gt;
&lt;td&gt;14 years from issuance&lt;/td&gt;
&lt;td&gt;&lt;a href=&#34;https://en.wikipedia.org/wiki/Patent_Act_of_1790&#34;&gt;Patent Act of 1790&lt;/a&gt;&lt;/td&gt;
&lt;/tr&gt;
&lt;tr class=&#34;even&#34;&gt;
&lt;td&gt;1836–1860&lt;/td&gt;
&lt;td&gt;21 years from issuance&lt;/td&gt;
&lt;td&gt;&lt;a href=&#34;https://en.wikipedia.org/wiki/Patent_Act_of_1836&#34;&gt;Patent Act of 1836&lt;/a&gt;&lt;/td&gt;
&lt;/tr&gt;
&lt;tr class=&#34;odd&#34;&gt;
&lt;td&gt;1861– 1994&lt;/td&gt;
&lt;td&gt;17 years from issuance&lt;/td&gt;
&lt;td&gt;Congress changed term&lt;/td&gt;
&lt;/tr&gt;
&lt;tr class=&#34;even&#34;&gt;
&lt;td&gt;1994 - now&lt;/td&gt;
&lt;td&gt;20 years from filing&lt;/td&gt;
&lt;td&gt;&lt;a href=&#34;https://en.wikipedia.org/wiki/Uruguay_Round_Agreements_Act&#34;&gt;Uruguay Round Agreements Act&lt;/a&gt;&lt;/td&gt;
&lt;/tr&gt;
&lt;/tbody&gt;
&lt;/table&gt;
&lt;p&gt;Table based on &lt;a href=&#34;https://en.wikipedia.org/wiki/Term_of_patent_in_the_United_States&#34;&gt;wikipedia&lt;/a&gt; and &lt;a href=&#34;https://www.uspto.gov/patent/laws-and-regulations/patent-term-calculator&#34;&gt;USPTO&lt;/a&gt;&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Reissue (RE######)&lt;/li&gt;
&lt;li&gt;Plant Patent (PP######) lasts for 20 years from the application date&lt;/li&gt;
&lt;li&gt;Design (D#######) lasts for 14 years from the granted date&lt;/li&gt;
&lt;li&gt;Additions or Improvements (AI#######)&lt;/li&gt;
&lt;li&gt;X Patents (X#######)&lt;/li&gt;
&lt;li&gt;H Documents (H#######)&lt;/li&gt;
&lt;li&gt;T Documents (T#######)&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;&lt;br&gt;&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Worldwide&lt;/strong&gt;&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;a href=&#34;https://www.epo.org/searching-for-patents/business/patstat.html#tab-1&#34;&gt;EPO and OECD&lt;/a&gt; data&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;https://www.wipo.int/econ_stat/en/economics/research/&#34;&gt;wipo&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;&lt;br&gt;
&lt;br&gt;&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Matching process with CRSP or Compustat&lt;/strong&gt;&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;a href=&#34;https://wrds-www.wharton.upenn.edu/pages/data/contributed-data/kpss-technological-innovation-resource-allocation-and-growth/&#34;&gt;KPSS Technological Innovation, Resource Allocation, and Growth&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;https://patents.darden.virginia.edu/documents/DataConstructionDetails_v01.pdf&#34;&gt;UVA Darden Global Corporate Patent Dataset&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;https://voices.uchicago.edu/miaoliu/data-page/&#34;&gt;Miao Liu&lt;/a&gt; Note that you need Bing API and use Python &lt;a href=&#34;https://github.com/danielm-github/patentsmatch_bingsearchapproach&#34;&gt;Github repo&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;https://users.nber.org/~jbessen/matchdoc.pdf&#34;&gt;NBER Guide&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
</description>
    </item>
    
    <item>
      <title>Linking Financial Databases (CRSP and Compustat)</title>
      <link>https://mikenguyen.netlify.app/post/link_crsp_compustat/</link>
      <pubDate>Tue, 08 Dec 2020 00:00:00 +0000</pubDate>
      <guid>https://mikenguyen.netlify.app/post/link_crsp_compustat/</guid>
      <description>
&lt;link href=&#34;https://mikenguyen.netlify.app/rmarkdown-libs/anchor-sections/anchor-sections.css&#34; rel=&#34;stylesheet&#34; /&gt;
&lt;script src=&#34;https://mikenguyen.netlify.app/rmarkdown-libs/anchor-sections/anchor-sections.js&#34;&gt;&lt;/script&gt;


&lt;p&gt;Information can be found in &lt;a href=&#34;https://www.otago.ac.nz/library/pdf/CRSPCompustatguide09.pdf&#34;&gt;CRSP/COMPUSTAT MERGED DATABASE GUIDE&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;Change Identifiers:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;strong&gt;Ticker&lt;/strong&gt;: can be reassign to another company - abbreviation used to uniquely identify publicly-traded shares of a stock&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;CUSIP&lt;/strong&gt;: A company can have multiple CUSIPS due to structural changes. - nine-character code assigned by the CUSIP Service Bureau to identify various securities&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;Permanent Identifiers&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;CRSP (maintained by Chicago BOoth CRSP)
&lt;ul&gt;
&lt;li&gt;&lt;strong&gt;PERMCO&lt;/strong&gt;: is a unique permanent company level identifier (even under name change)&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;PERMNO&lt;/strong&gt;: is a unique stock (share class) level identifier. One company can have multiple share classes. (1 PERMNO -&amp;gt; 1 PERMCO, 1 -&amp;gt; multiple PERMNOs)&lt;/li&gt;
&lt;/ul&gt;&lt;/li&gt;
&lt;li&gt;Compustat-Capital IQ (maintained by S&amp;amp;P)
&lt;ul&gt;
&lt;li&gt;&lt;strong&gt;GVKEY&lt;/strong&gt;: is a unique number assigned to each company.&lt;/li&gt;
&lt;/ul&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;table&gt;
&lt;thead&gt;
&lt;tr class=&#34;header&#34;&gt;
&lt;th&gt;&lt;/th&gt;
&lt;th&gt;CRSP&lt;/th&gt;
&lt;th&gt;COMPUSTAT&lt;/th&gt;
&lt;/tr&gt;
&lt;/thead&gt;
&lt;tbody&gt;
&lt;tr class=&#34;odd&#34;&gt;
&lt;td&gt;Time since&lt;/td&gt;
&lt;td&gt;1925&lt;/td&gt;
&lt;td&gt;1950&lt;/td&gt;
&lt;/tr&gt;
&lt;tr class=&#34;even&#34;&gt;
&lt;td&gt;Companies&lt;/td&gt;
&lt;td&gt;listed in U.S. Exchange&lt;/td&gt;
&lt;td&gt;U.S. + Canada&lt;/td&gt;
&lt;/tr&gt;
&lt;tr class=&#34;odd&#34;&gt;
&lt;td&gt;Report&lt;/td&gt;
&lt;td&gt;Daily and Monthly&lt;/td&gt;
&lt;td&gt;Quarterly and Annually&lt;/td&gt;
&lt;/tr&gt;
&lt;/tbody&gt;
&lt;/table&gt;
</description>
    </item>
    
  </channel>
</rss>
